{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97370ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install llama-index llama-index-embeddings-openai qdrant-client llama-index-vector-stores-qdrant llama-index llama-index-llms-openai llama-index-vector-stores-faiss faiss-cpu llama-index-llms-anthropic tavily-python llama-index-experimental llama-index-llms-cerebras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d72ed41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Import LlamaIndex components\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.workflow import Event, Workflow, Context, StopEvent, step\n",
    "from llama_index.core.workflow import StartEvent\n",
    "from llama_index.llms.cerebras import Cerebras\n",
    "import pandas as pd\n",
    "import re\n",
    "import functools\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "# Context is already imported above\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from pandas_helper import PandasHelper\n",
    "from events import *\n",
    "from tools.execute_pd_tool import *\n",
    "from tools.save_dataframe_tool import *\n",
    "from agents import *\n",
    "from tools.execute_pd_tool import execute_pandas_query_tool\n",
    "from tools.save_dataframe_tool import save_dataframe_tool\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# cerebras_model_name = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct\"\n",
    "# llm_cerebras = Cerebras(model=cerebras_model_name, api_key=)\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or getpass(\"Enter OPENAI_API_KEY: \")\n",
    "llm = OpenAI(model=\"gpt-4.1-2025-04-14\", api_key=OPENAI_API_KEY, temperature=0.5, max_tokens=4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55d13caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalysisFlow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    async def setup(self, ctx: Context, ev: StartEvent) -> InitialAssessmentEvent: \n",
    "        \"\"\"Initialize the agents and setup the workflow\"\"\"\n",
    "\n",
    "        # --- Load data and create Pandas Query Engine ---\n",
    "        try:\n",
    "            df = pd.read_csv(ev.dataset_path)\n",
    "            query_engine = PandasQueryEngine(df=df, llm=llm, verbose=True)\n",
    "\n",
    "            # Store the DataFrame and query engine in the context\n",
    "            await ctx.set(\"dataframe\", df)\n",
    "            await ctx.set(\"query_engine\", query_engine)\n",
    "            await ctx.set(\"original_path\", ev.dataset_path)\n",
    "\n",
    "            print(f\"Successfully loaded {ev.dataset_path} and created PandasQueryEngine.\")\n",
    "\n",
    "            self.data_prep_agent, self.data_analysis_agent = create_agents()\n",
    "\n",
    "            # --- Get initial stats for the next step ---\n",
    "            initial_info_str = \"Could not retrieve initial stats.\"\n",
    "            column_info_dict = {}\n",
    "            try:\n",
    "                if hasattr(query_engine, 'aquery'):\n",
    "                     response = await query_engine.aquery(\"Show the shape of the dataframe (number of rows and columns) and the output of df.describe(include='all')\")\n",
    "                else:\n",
    "                     response = query_engine.query(\"Show the shape of the dataframe (number of rows and columns) and the output of df.describe(include='all')\")\n",
    "                initial_info_str = str(response)\n",
    "\n",
    "                missing_counts = df.isna().sum().to_dict()\n",
    "                dtypes = df.dtypes.astype(str).to_dict()\n",
    "                column_info_dict = {\"dtypes\": dtypes, \"missing_counts\": missing_counts}\n",
    "                print(f\"--- Initial Info Gathered ---\\n{initial_info_str}\\nColumn Details:\\n{column_info_dict}\\n-----------------------------\")\n",
    "                # Store these in context for the consultation step later\n",
    "                await ctx.set(\"stats_summary\", initial_info_str)\n",
    "                await ctx.set(\"column_info\", column_info_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not query initial info from engine during setup: {e}\")\n",
    "                initial_info_str = f\"Columns: {df.columns.tolist()}\" \n",
    "                column_info_dict = {\"columns\": df.columns.tolist()} \n",
    "                await ctx.set(\"stats_summary\", initial_info_str) \n",
    "                await ctx.set(\"column_info\", column_info_dict) \n",
    "            \n",
    "\n",
    "            \n",
    "            return InitialAssessmentEvent( \n",
    "                stats_summary=initial_info_str,\n",
    "                column_info=column_info_dict,\n",
    "                original_path=ev.dataset_path,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during setup: Failed to load {ev.dataset_path} or create engine. Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc() \n",
    "            raise ValueError(f\"Setup failed: {e}\")\n",
    "        \n",
    "    @step\n",
    "    async def data_preparation(self, ctx: Context, ev: InitialAssessmentEvent) -> DataAnalysisEvent: \n",
    "        \"\"\"Use the data prep agent to suggest cleaning/preparation based on schema.\"\"\"\n",
    "\n",
    "\n",
    "        initial_info = ev.stats_summary # Get stats from the event\n",
    "        column_info = ev.column_info\n",
    "\n",
    "        prep_prompt = (\n",
    "            f\"The dataset (from {ev.original_path}) has the following shape and summary statistics:\\\\n{initial_info}\\\\nColumn Details:\\\\n{column_info}\\\\n\\\\n\"\n",
    "            f\"Based *only* on these statistics, describe the necessary data preparation steps. \"\n",
    "            f\"Specifically mention potential issues like outliers (e.g., in 'Distance' max value), missing values (e.g., count mismatch in 'Time'), \"\n",
    "            f\"and data quality issues in categorical columns (e.g., unique count vs expected for 'Mode', potential typos like 'Bas', 'Cra', 'Walt'). \"\n",
    "            f\"Suggest specific actions like imputation for 'Time', outlier investigation/handling for 'Distance', and checking unique values/correcting typos in 'Mode'. \"\n",
    "            f\"Focus on describing *what* needs to be done and *why* based *strictly* on the provided stats. **Do NOT suggest normalization or scaling steps.** If no issues are apparent from the stats, state that clearly. ALWAYS provide a description.\"\n",
    "            )\n",
    "        result = self.data_prep_agent.chat(prep_prompt)\n",
    "\n",
    "        prepared_data_description = None\n",
    "        if hasattr(result, 'response'):\n",
    "            prepared_data_description = result.response\n",
    "            if not prepared_data_description:\n",
    "                prepared_data_description = \"Agent returned an empty description despite the prompt.\"\n",
    "                print(\"Warning: Agent response attribute was empty.\")\n",
    "\n",
    "        else:\n",
    "            prepared_data_description = \"Could not extract data preparation description from agent response.\"\n",
    "            print(f\"Warning: Agent response does not have expected 'response' attribute. Full result: {result}\")\n",
    "\n",
    "\n",
    "        print(f\"--- Prep Agent Description Output ---\\\\n{prepared_data_description}\\\\n------------------------------------\")\n",
    "\n",
    "        # Store the *agent's suggested* description (before human input)\n",
    "        await ctx.set(\"agent_prepared_data_description\", prepared_data_description)\n",
    "\n",
    "\n",
    "        return DataAnalysisEvent(\n",
    "            prepared_data_description=prepared_data_description, # Agent's initial suggestion\n",
    "            original_path=ev.original_path\n",
    "        )\n",
    "\n",
    "    \n",
    "    @step\n",
    "    async def human_consultation(self, ctx: Context, ev: DataAnalysisEvent) -> DataAnalysisEvent: \n",
    "        \"\"\"Analyzes initial assessment, asks user for cleaning decisions using numbered options.\"\"\" \n",
    "        print(\"--- Running Human Consultation Step ---\")\n",
    "        agent_suggestion = ev.prepared_data_description \n",
    "        original_path = ev.original_path\n",
    "        stats_summary = await ctx.get(\"stats_summary\", \"Stats not available.\")\n",
    "        column_info = await ctx.get(\"column_info\", {})\n",
    "\n",
    "     \n",
    "        consultation_agent = FunctionCallingAgent.from_tools(\n",
    "            tools=[], \n",
    "            llm=llm,\n",
    "            verbose=True,\n",
    "            system_prompt=(\n",
    "                \"You are a data cleaning assistant. You are given an initial analysis and suggested cleaning steps. \"\n",
    "                \"Your task is to formulate concise, **numbered options** for the user based *only* on the issues explicitly identified in the analysis (missing values, outliers, duplicates, data quality). \"\n",
    "                \"**If no issues were identified for a category (e.g., no missing values found), do NOT ask about it.** \"\n",
    "                \"For each identified issue, present the finding and suggest 1-3 common handling strategies as numbered options (e.g., 1. Fill median, 2. Fill mean, 3. Drop rows). \"\n",
    "                \"Start numbering options from 1 and continue sequentially across all issues. \"\n",
    "                \"Combine these into a single, clear message asking the user to reply with the **numbers** of their chosen options, separated by semicolons. Use the provided analysis as context.\\n\"\n",
    "                \"Example Output Format (if missing values and outliers were found, but no duplicates or quality issues):\\n\"\n",
    "                \"Based on the analysis:\\n\"\n",
    "                \"Missing Values ('Time'): 3 found.\\n\"\n",
    "                \"  1. Fill median\\n\"\n",
    "                \"  2. Fill mean\\n\"\n",
    "                \"  3. Drop rows\\n\"\n",
    "                \"Outliers ('Distance'): Max 99.0 is high.\\n\"\n",
    "                \"  4. Keep outliers\\n\"\n",
    "                \"  5. Remove outlier rows\\n\"\n",
    "                \"  6. Cap outliers at 95th percentile\\n\"\n",
    "                \"Please reply with the numbers of your chosen options, separated by semicolons (e.g., '1;5'): \"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        consultation_prompt = f\"Formulate numbered user questions based on this analysis/suggestion:\\\\n<analysis>\\\\n{agent_suggestion}\\\\n</analysis>\\\\n\\\\nAdditional Context:\\\\nStats Summary:\\\\n{stats_summary}\\\\nColumn Info:\\\\n{column_info}\"\n",
    "        print(f\"--- Prompting Consultation Agent ---\\\\n{consultation_prompt}\\\\n---------------------------------\")\n",
    "        agent_response = await consultation_agent.achat(consultation_prompt)\n",
    "        consultation_message = agent_response.response if hasattr(agent_response, 'response') else \"Could not generate consultation message.\"\n",
    "\n",
    "        print(f\"--- Consultation Message ---\\\\n{consultation_message}\\\\n----------------------------\")\n",
    "\n",
    "        # --- Emit event to request user input ---\n",
    "        issues_placeholder = {\"message\": consultation_message} # Keep original message for context\n",
    "        print(\"Human Consultation: Emitting CleaningInputRequiredEvent...\")\n",
    "        ctx.write_event_to_stream(\n",
    "            CleaningInputRequiredEvent(\n",
    "                issues=issues_placeholder,\n",
    "                prompt_message=consultation_message \n",
    "            )\n",
    "        )\n",
    "\n",
    "        # --- Wait for user response (expecting numbers) ---\n",
    "        print(\"Human Consultation: Waiting for CleaningResponseEvent...\")\n",
    "        response_event = await ctx.wait_for_event(CleaningResponseEvent)\n",
    "        print(\"Human Consultation: Received CleaningResponseEvent.\")\n",
    "        \n",
    "        user_input_numbers = response_event.user_choices.get(\"numbers\", \"\") # Get raw numeric string\n",
    "        print(f\"User chose numbers: {user_input_numbers}\")\n",
    "\n",
    "        # --- Agent to Translate Numbers to Description ---\n",
    "        translation_agent = FunctionCallingAgent.from_tools(\n",
    "            tools=[],\n",
    "            llm=llm,\n",
    "            verbose=True,\n",
    "            system_prompt=(\n",
    "                \"You are given a text containing numbered options for data cleaning and a string containing the numbers selected by the user (separated by semicolons). \"\n",
    "                \"Your task is to generate a clear, descriptive summary of the actions corresponding to the selected numbers. \"\n",
    "                \"This summary will be used as instructions for another agent. \"\n",
    "                \"Format the output as a list of actions.\\n\"\n",
    "                \"Example Input:\\n\"\n",
    "                \"Options Text: 'Based on the analysis:\\\\nMissing Values ('Time'): 3 found.\\\\n  1. Fill median\\\\n  2. Fill mean\\\\nOutliers ('Distance'): Max 99.0 is high.\\\\n  3. Keep outliers\\\\n  4. Remove outlier rows'\\n\"\n",
    "                \"Selected Numbers: '1;4'\\n\"\n",
    "                \"Example Output:\\n\"\n",
    "                \"Apply the following user-specified cleaning steps:\\n\"\n",
    "                \"- For missing values in 'Time', apply strategy: Fill median.\\n\"\n",
    "                \"- For outliers in 'Distance', apply strategy: Remove outlier rows.\\n\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        translation_prompt = (\n",
    "            f\"Translate the selected numbers into a descriptive action plan.\\n\\n\"\n",
    "            f\"Options Text:\\n'''\\n{consultation_message}\\n'''\\n\\n\"\n",
    "            f\"Selected Numbers: '{user_input_numbers}'\\n\\n\"\n",
    "            f\"Generate the descriptive action plan:\"\n",
    "        )\n",
    "        print(f\"--- Prompting Translation Agent ---\\\\n{translation_prompt}\\\\n---------------------------------\")\n",
    "        translation_response = await translation_agent.achat(translation_prompt)\n",
    "        user_approved_description = translation_response.response if hasattr(translation_response, 'response') else f\"Could not translate choices: {user_input_numbers}\"\n",
    "\n",
    "        # Handle potential empty description from translation agent\n",
    "        if not user_approved_description.strip() or \"Could not translate\" in user_approved_description:\n",
    "             print(f\"Warning: Translation agent failed or returned empty description. Using fallback.\")\n",
    "             user_approved_description = f\"Apply user choices corresponding to numbers: {user_input_numbers} based on the options provided.\"\n",
    "\n",
    "\n",
    "        print(f\"--- Generated User-Approved Preparation Description ---\\\\n{user_approved_description}\\\\n---------------------------------------\")\n",
    "\n",
    "        # Pass the translated description to the next step\n",
    "        return DataAnalysisEvent(prepared_data_description=user_approved_description, original_path=original_path)\n",
    "\n",
    "\n",
    "    @step\n",
    "    async def data_modification(self, ctx: Context, ev: DataAnalysisEvent) -> ModificationCompleteEvent: \n",
    "        \"\"\"Applies the data modifications using a dedicated agent based on user input.\"\"\"\n",
    "        print(\"--- Running Data Modification Step ---\") # Added print statement\n",
    "        df: pd.DataFrame = await ctx.get(\"dataframe\")\n",
    "        query_engine: PandasQueryEngine = await ctx.get(\"query_engine\")\n",
    "        original_path = ev.original_path # Get path from the event\n",
    "\n",
    "        pandas_helper = PandasHelper(df, query_engine) \n",
    "        pandas_query_tool_local = FunctionTool.from_defaults(\n",
    "            async_fn=pandas_helper.execute_pandas_query,\n",
    "            name=\"execute_pandas_query_tool\",\n",
    "            description=pandas_helper.execute_pandas_query.__doc__\n",
    "        )\n",
    "\n",
    "        modification_agent = FunctionCallingAgent.from_tools(\n",
    "            tools=[pandas_query_tool_local],\n",
    "            llm=llm,\n",
    "            verbose=True,\n",
    "            system_prompt=(\n",
    "                \"You are a data modification agent. Your task is to execute the pandas commands \"\n",
    "                \"(using 'df' and the 'execute_pandas_query_tool') described in the provided text \"\n",
    "                \"to clean and modify the DataFrame based on USER choices. Focus *only* on executing the modification steps accurately.\" # Updated prompt\n",
    "            )\n",
    "        )\n",
    "\n",
    "        modification_request = (\n",
    "            f\"Apply the following USER-APPROVED data preparation steps using pandas commands with the 'execute_pandas_query_tool':\\n\" # Emphasize user approval\n",
    "            f\"<preparation_description>\\n{ev.prepared_data_description}\\n</preparation_description>\" # Use description from event\n",
    "        )\n",
    "        print(f\"--- Prompting Data Modification Agent ---\\\\n{modification_request}\\\\n------------------------------------\")\n",
    "\n",
    "        \n",
    "        await modification_agent.achat(modification_request)\n",
    "\n",
    "        # --- Update workflow context with the final DataFrame state from the helper ---\n",
    "        final_df = pandas_helper.get_final_dataframe() \n",
    "        await ctx.set(\"dataframe\", final_df)\n",
    "        try:\n",
    "            # Ensure the main query engine used by subsequent steps reflects the changes\n",
    "            query_engine._df = final_df\n",
    "            await ctx.set(\"query_engine\", query_engine)\n",
    "        except AttributeError:\n",
    "            print(\"Warning: Could not update main query engine's _df in context after modification step.\")\n",
    "\n",
    "        print(\"--- Data Modification Complete ---\")\n",
    "        \n",
    "        return ModificationCompleteEvent(original_path=original_path) \n",
    "\n",
    "\n",
    "    @step\n",
    "    async def analysis_reporting(self, ctx: Context, ev: ModificationCompleteEvent) -> StopEvent:\n",
    "        \"\"\"Performs analysis on the modified data, generates a report, and saves.\"\"\"\n",
    "        df: pd.DataFrame = await ctx.get(\"dataframe\") # Get the modified DF\n",
    "        query_engine: PandasQueryEngine = await ctx.get(\"query_engine\")\n",
    "        original_path: str = ev.original_path # Get path from the event\n",
    "\n",
    "        pandas_helper = PandasHelper(df, query_engine) # Helper with modified data\n",
    "\n",
    "        pandas_query_tool_local = FunctionTool.from_defaults(\n",
    "             async_fn=pandas_helper.execute_pandas_query,\n",
    "             name=\"execute_pandas_query_tool\",\n",
    "             description=pandas_helper.execute_pandas_query.__doc__\n",
    "        )\n",
    "        save_df_tool_local = FunctionTool.from_defaults(\n",
    "             async_fn=pandas_helper.save_dataframe,\n",
    "             name=\"save_dataframe_tool\",\n",
    "             description=pandas_helper.save_dataframe.__doc__\n",
    "        )\n",
    "\n",
    "        analysis_reporting_agent = FunctionCallingAgent.from_tools(\n",
    "            tools=[pandas_query_tool_local, save_df_tool_local],\n",
    "            llm=llm,\n",
    "            verbose=True,\n",
    "            system_prompt=(\n",
    "                \"You are a data analysis and reporting agent. You work with an already modified DataFrame based on user decisions.\\\\n\" # Added user decisions context\n",
    "                \"Your tasks are:\\\\n\"\n",
    "                \"1. Perform analysis queries on the current DataFrame using 'execute_pandas_query_tool'.\\\\n\"\n",
    "                \"2. Generate a concise Markdown report summarizing key findings from your analysis.\\\\n\"\n",
    "                \"3. Save the current DataFrame using the 'save_dataframe_tool'.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        path_parts = os.path.splitext(original_path)\n",
    "        modified_file_path = f\"{path_parts[0]}_modified{path_parts[1]}\"\n",
    "\n",
    "        analysis_request = (\n",
    "            f\"The DataFrame (originally from {original_path}) has been modified based on prior user-approved cleaning steps.\\\\n\" # Updated context\n",
    "            f\"Now, please perform the following actions:\\\\n\"\n",
    "            f\"1. Perform a brief analysis on the modified data. For example, check the description of the 'Time' column (df['Time'].describe()), the unique values in 'Mode' (df['Mode'].unique()), and the description of 'Distance' (df['Distance'].describe()). Use the 'execute_pandas_query_tool'.\\\\n\"\n",
    "            f\"2. Generate a Markdown report summarizing the key findings from your analysis of the modified data.\\\\n\"\n",
    "            f\"3. Save the current DataFrame to the following path using the 'save_dataframe_tool': '{modified_file_path}'\"\n",
    "        )\n",
    "\n",
    "        print(f\"--- Prompting Analysis & Reporting Agent ---\\\\n{analysis_request}\\\\n------------------------------------\")\n",
    "\n",
    "        \n",
    "        agent_response = await analysis_reporting_agent.achat(analysis_request)\n",
    "\n",
    "        \n",
    "        final_df = pandas_helper.get_final_dataframe() \n",
    "        await ctx.set(\"dataframe\", final_df)\n",
    "\n",
    "       \n",
    "        final_report = \"Agent did not provide a valid report.\"\n",
    "        if hasattr(agent_response, 'response') and agent_response.response:\n",
    "             final_report = agent_response.response\n",
    "             \n",
    "        else:\n",
    "             print(f\"Warning: Agent response might not be the expected report. Full result: {agent_response}\")\n",
    "             final_report = str(agent_response) \n",
    "\n",
    "        print(f\"--- Analysis & Reporting Agent Final Response (Report) ---\\\\n{final_report}\\\\n------------------------------------------\")\n",
    "        await ctx.set(\"final_report\", final_report)\n",
    "        return StopEvent(result={\"final_report\": final_report})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03e77965",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_workflow(dataset_path):\n",
    "    \"\"\"Run the data analysis workflow on the given dataset\"\"\"\n",
    "\n",
    "    workflow = DataAnalysisFlow(timeout=300, verbose=True)\n",
    "\n",
    "    try:\n",
    "        handler = workflow.run(\n",
    "            dataset_path=dataset_path,\n",
    "        )\n",
    "\n",
    "       \n",
    "        async for event in handler.stream_events():\n",
    "            print(f\"Run Workflow Loop: Received event: {type(event).__name__}\")\n",
    "\n",
    "            if isinstance(event, CleaningInputRequiredEvent):\n",
    "                print(\"Run Workflow Loop: Handling CleaningInputRequiredEvent.\")\n",
    "                user_input_numbers = input(event.prompt_message) \n",
    "\n",
    "                print(f\"Run Workflow Loop: User entered numbers: {user_input_numbers}\")\n",
    "                print(\"Run Workflow Loop: Sending CleaningResponseEvent...\")\n",
    "               \n",
    "                handler.ctx.send_event(\n",
    "                    CleaningResponseEvent(user_choices={\"numbers\": user_input_numbers.strip()})\n",
    "                )\n",
    "                print(\"Run Workflow Loop: Sent CleaningResponseEvent.\")\n",
    "\n",
    "        final_result_dict = await handler\n",
    "\n",
    "        print(\"\\n==== Final Report ====\")\n",
    "        final_report = final_result_dict.get('final_report', 'N/A')\n",
    "        print(final_report)\n",
    "\n",
    "        return final_result_dict\n",
    "    except Exception as e:\n",
    "         print(f\"Workflow failed: {e}\")\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "         return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "663b69ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step setup\n",
      "Successfully loaded C:\\Users\\anteb\\Desktop\\Courses\\Projects\\data_analysis_ai\\data_analysis_agent\\Commute_Times_V1.csv and created PandasQueryEngine.\n",
      "Error during setup: Failed to load C:\\Users\\anteb\\Desktop\\Courses\\Projects\\data_analysis_ai\\data_analysis_agent\\Commute_Times_V1.csv or create engine. Error: name 'FunctionTool' is not defined\n",
      "Run Workflow Loop: Received event: StopEvent\n",
      "Workflow failed: Error in step 'setup': Setup failed: name 'FunctionTool' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anteb\\AppData\\Local\\Temp\\ipykernel_66696\\1669689835.py\", line 19, in setup\n",
      "    self.data_prep_agent, self.data_analysis_agent = create_agents()\n",
      "                                                     ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anteb\\Desktop\\Courses\\Projects\\data_analysis_ai\\data_analysis_agent\\agents.py\", line 6, in create_agents\n",
      "NameError: name 'FunctionTool' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anteb\\AppData\\Local\\Temp\\ipykernel_66696\\1669689835.py\", line 19, in setup\n",
      "    self.data_prep_agent, self.data_analysis_agent = create_agents()\n",
      "                                                     ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anteb\\Desktop\\Courses\\Projects\\data_analysis_ai\\data_analysis_agent\\agents.py\", line 6, in create_agents\n",
      "NameError: name 'FunctionTool' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py\", line 500, in _step_worker\n",
      "    new_ev = await instrumented_step(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py\", line 368, in async_wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anteb\\AppData\\Local\\Temp\\ipykernel_66696\\1669689835.py\", line 56, in setup\n",
      "    raise ValueError(f\"Setup failed: {e}\")\n",
      "ValueError: Setup failed: name 'FunctionTool' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anteb\\AppData\\Local\\Temp\\ipykernel_66696\\2144215152.py\", line 27, in run_workflow\n",
      "    final_result_dict = await handler\n",
      "                        ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py\", line 394, in _run_workflow\n",
      "    raise exception_raised\n",
      "  File \"c:\\Users\\anteb\\anaconda3\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anteb\\anaconda3\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py\", line 508, in _step_worker\n",
      "    raise WorkflowRuntimeError(\n",
      "llama_index.core.workflow.errors.WorkflowRuntimeError: Error in step 'setup': Setup failed: name 'FunctionTool' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = r\"C:\\Users\\anteb\\Desktop\\Courses\\Projects\\data_analysis_ai\\data_analysis_agent\\Commute_Times_V1.csv\"\n",
    "await run_workflow(dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
